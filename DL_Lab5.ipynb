{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DE8ElXCulbYL"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/wingated/cs474_labs_f2019/blob/master/DL_Lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "# Lab 5: Style Transfer\n",
    "\n",
    "## Objectives\n",
    "- To explore an alternative use of DNNs by implementing the style transfer algorithm ([Gatys et. al. 2016](https://arxiv.org/pdf/1508.06576.pdf)).\n",
    "- To understand the importance of a complex loss function.\n",
    "- To see how we can optimize not only over network parameters, but over other objects (such as images) as well.\n",
    "\n",
    "## Deliverable\n",
    "For this lab, you will need to implement the style transfer algorithm of Gatys et al.\n",
    "\n",
    "* You must extract statistics from the content and style images\n",
    "* You must formulate an optimization problem over an input image\n",
    "* You must optimize the image to match both style and content\n",
    "\n",
    "In your jupyter notebook, you should turn in the following:\n",
    "\n",
    "* The final image that you generated\n",
    "* Your code\n",
    "* A description of the equations from (Gatys et. al. 2016) -- see the bottom of the notebook for details.\n",
    "\n",
    "An example image that I generated is shown below\n",
    "\n",
    "![](https://github.com/wingated/cs474_labs/blob/master/images/style1.png?raw=true)\n",
    "\n",
    "## Grading standards\n",
    "Your code will be graded on the following:\n",
    "\n",
    "* 35% Correct extraction of statistics\n",
    "* 35% Correct construction of loss function in a loss class\n",
    "* 10% Plain English description of equations from (Gatys et. al. 2016) at the bottom of the notebook\n",
    "* 10% Correct initialization and optimization of image variable\n",
    "* 10% Awesome looking final image\n",
    "\n",
    "Note: You may reference other implementations for ideas, but you are on your honor not to copy/paste other people's code.\n",
    "\n",
    "## Description:\n",
    "\n",
    "For this lab, you should implement the style transfer algorithm referenced above.\n",
    "To do this, you will need to unpack the given images.\n",
    "Since we want you to focus on implementing the paper and the loss function, \n",
    "we will give you the code for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VdQhJmJJYOt_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, utils, datasets\n",
    "from tqdm import tqdm\n",
    "from torch.nn.parameter import Parameter\n",
    "import pdb\n",
    "import torchvision\n",
    "import os\n",
    "import gzip\n",
    "import tarfile\n",
    "import gc\n",
    "from PIL import Image\n",
    "import io\n",
    "from IPython.core.ultratb import AutoFormattedTB\n",
    "__ITB__ = AutoFormattedTB(mode = 'Verbose', color_scheme='LightBg', tb_offset = 1)\n",
    "\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvGqSVnGec12"
   },
   "outputs": [],
   "source": [
    "# Use this code to upload your own images\n",
    "\n",
    "load_and_normalize = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def upload():\n",
    "  print('Upload Content Image')\n",
    "  file_dict = files.upload()\n",
    "  content_path = io.BytesIO(file_dict[next(iter(file_dict))])\n",
    "\n",
    "  print('\\nUpload Style Image')\n",
    "  file_dict = files.upload()\n",
    "  style_path = io.BytesIO(file_dict[next(iter(file_dict))])\n",
    "  return content_path, style_path\n",
    "\n",
    "content_path, style_path = upload()\n",
    "\n",
    "print(\"Content Path: {}\".format(content_path))\n",
    "print(\"Style Path: {}\".format(style_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IxKpna4llbYb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# After the images are uploaded on to the local filesystem, you can use:\n",
    "content_image_orig = Image.open(content_path)\n",
    "content_image = load_and_normalize(np.array(content_image_orig)).unsqueeze(0).cuda()\n",
    "style_image_orig = Image.open(style_path)\n",
    "style_image = load_and_normalize(np.array(style_image_orig)).unsqueeze(0).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "msyhi4HofaR9"
   },
   "outputs": [],
   "source": [
    "# Display the images\n",
    "toPIL = transforms.ToPILImage()  \n",
    "\n",
    "def display(tensor, title=None):\n",
    "    image = tensor.cpu().clone()  \n",
    "    image = image.squeeze(0)    \n",
    "    image = toPIL(image)\n",
    "    plt.imshow(image)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "plt.figure()\n",
    "display(style_image, title='Style Image')\n",
    "\n",
    "plt.figure()\n",
    "display(content_image, title='Content Image')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rf0fV_SSSKEo"
   },
   "source": [
    "___\n",
    "\n",
    "### Part 1\n",
    "Create a network instance to extract the layers needed for statistics\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "* Correctly initialize a VGGIntermediate object to extract style and content\n",
    "* Gather content statistics from the outputs of intermediate layers for the content image\n",
    "* Gather style statistics for the style image\n",
    "\n",
    "**DONE:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nonAvCqYgL6"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class Normalization(nn.Module):\n",
    "  def __init__(self, mean=torch.tensor([0.485, 0.456, 0.406]).cuda(), std=torch.tensor([0.229, 0.224, 0.225]).cuda()):\n",
    "      super(Normalization, self).__init__()\n",
    "      self.mean = torch.tensor(mean).view(-1, 1, 1)\n",
    "      self.std = torch.tensor(std).view(-1, 1, 1)\n",
    "\n",
    "  def forward(self, img):\n",
    "      return (img - self.mean) / self.std\n",
    "\n",
    "class VGGIntermediate(nn.Module):\n",
    "  def __init__(self, requested=[]):\n",
    "    super(VGGIntermediate, self).__init__()\n",
    "    self.norm = Normalization().eval()\n",
    "    self.intermediates = {}\n",
    "    self.vgg = models.vgg16(pretrained=True).features.eval()\n",
    "    for i, m in enumerate(self.vgg.children()):\n",
    "        if isinstance(m, nn.ReLU):   # we want to set the relu layers to NOT do the relu in place. \n",
    "          m.inplace = False          # the model has a hard time going backwards on the in place functions. \n",
    "        \n",
    "        if i in requested:\n",
    "          def curry(i):\n",
    "            def hook(module, input, output):\n",
    "              self.intermediates[i] = output\n",
    "            return hook\n",
    "          m.register_forward_hook(curry(i))\n",
    "    \n",
    "  def forward(self, x):\n",
    "    self.vgg(self.norm(x))  \n",
    "    return self.intermediates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "deG45N1AYi6O"
   },
   "outputs": [],
   "source": [
    "vgg_names = [\"conv1_1\", \"relu1_1\", \"conv1_2\", \"relu1_2\", \"maxpool1\", \"conv2_1\", \"relu2_1\", \"conv2_2\", \"relu2_2\", \"maxpool2\", \"conv3_1\", \"relu3_1\", \"conv3_2\", \"relu3_2\", \"conv3_3\", \"relu3_3\",\"maxpool3\", \"conv4_1\", \"relu4_1\", \"conv4_2\", \"relu4_2\", \"conv4_3\", \"relu4_3\",\"maxpool4\", \"conv5_1\", \"relu5_1\", \"conv5_2\", \"relu5_2\", \"conv5_3\", \"relu5_3\",\"maxpool5\"]\n",
    "\n",
    "# Choose the layers to use for style and content transfer\n",
    "\n",
    "# Create the vgg network in eval mode\n",
    "#  with our forward method that returns the outputs of the intermediate layers we requested\n",
    "\n",
    "# Cache the outputs of the content and style layers for their respective images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-3GS-qHTp0a"
   },
   "source": [
    "___\n",
    "\n",
    "### Part 2\n",
    "Create modules for the style and content loss\n",
    "\n",
    "Note: You may want to try part 4 before implementing the losses to ensure you understand how style transfer loss works.\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "* Create a module that calculates the content loss in the forward method, compared to some precalculated targets stored in the object\n",
    "* Create a module that calculates the style loss in the forward method using a gram matrix, compared to some precalculated targets stored in the object\n",
    "\n",
    "**DONE:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjyA3hK7koqs"
   },
   "outputs": [],
   "source": [
    "def gram_matrix(input):\n",
    "   pass\n",
    "  \n",
    "class ContentLoss(nn.Module):\n",
    "  pass\n",
    "    \n",
    "class StyleLoss(nn.Module):\n",
    "  pass\n",
    "\n",
    "# Instantiate a content loss module for each content layer \n",
    "#  with the content reference image outputs for that layer for comparison\n",
    "\n",
    "# Instantiate a style loss module for each style layer \n",
    "#  with the style reference image outputs for that layer for comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z68Rq165ULGj"
   },
   "source": [
    "___\n",
    "\n",
    "### Part 3\n",
    "Create and run a method that minimizes the content and style loss for a copy of the content image\n",
    "\n",
    "Note that the content loss should be zero if you take out the style loss. Why is that?\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "* Use an Adam optimizer (try learning rate of .1, but feel free to experiment)\n",
    "* Show both the content and the style loss every 50 steps\n",
    "* Ensure that the outputs don't go out of range (clamp them)\n",
    "* Display the tensor as an image!\n",
    "* Experiment with different hyperparameters or network layers until you're satisfied with your final image\n",
    "\n",
    "**DONE:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zflDDObAflen"
   },
   "outputs": [],
   "source": [
    "# Start with a copy of the content image\n",
    "\n",
    "# Set the optimizer to update the image\n",
    "# (Set requires_grad to True on the image to allow it to accumulate a gradient)\n",
    "\n",
    "# Run the optimizer on the images to change the image\n",
    "#  using the loss of the style and content layers\n",
    "#  to backpropagate errors \n",
    "  \n",
    "# Show the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T1qr7O2wpSq8"
   },
   "source": [
    "### Part 4\n",
    "\n",
    "Show that you understand style transfer by describing the key equations of (Gatys 2016) in your own words.\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "- Describe equation (1) on p. 10 of (Gatys 2016) in plain English, including the meaning of all variables and subscripts.\n",
    "- Describe equation (3) on p. 11 of (Gatys 2016) in plain English, including the meaning of all variables and subscripts.\n",
    "- Describe equation (4) on p. 11 of (Gatys 2016) in plain English, including the meaning of all variables and subscripts.\n",
    "- Describe equation (5) on p. 11 of (Gatys 2016) in plain English, including the meaning of all variables and subscripts.\n",
    "\n",
    "**DONE:**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
