{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rEwpv0GZ_CrT"
   },
   "source": [
    "<a \n",
    "href=\"https://colab.research.google.com/github/wingated/cs474_labs_f2019/blob/master/DL_Lab10.ipynb\"\n",
    "  target=\"_parent\">\n",
    "  <img\n",
    "    src=\"https://colab.research.google.com/assets/colab-badge.svg\"\n",
    "    alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xnoEhAVvBcMj"
   },
   "source": [
    "# Lab 10: Transfer Learning/Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sBOvJdJfkXIL"
   },
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GiuvTUWOjtBC"
   },
   "source": [
    "### Objective\n",
    "\n",
    "- Gain experience fine-tuning pre-trained models to domain-specific applications.\n",
    "\n",
    "### Deliverable\n",
    "\n",
    "For this lab you will submit an ipython notebook via learning suite. The bulk of the work is in modifying fine-tuning a pre-trained ResNet. Fine-tuning the GPT-2 language model is pretty easy. The provided code works as is; you will just have to swap in your own text dataset.\n",
    "\n",
    "### Grading\n",
    "\n",
    "- 35% Create a dataset class for your own dataset\n",
    "- 35% Create a network class that wraps a pretrained ResNet\n",
    "- 20% Implement unfreezing in the network class\n",
    "- 10% Fine-tune GPT-2 on your own dataset\n",
    "\n",
    "### Tips\n",
    "- Your life will be better if you download a dataset that already has the data in the expected format for ImageFolder (make sure to read the documentation!). The datasets recommended below are in the correct format.\n",
    "- Get the CNN working on the provided dataset (bird species classification) before swapping in your own.\n",
    "- For reference on freezing/unfreezing network weights, see [this github gist](https://gist.github.com/jcjohnson/6e41e8512c17eae5da50aebef3378a4c)\n",
    "- For training GPT-2, first try the medium-size (355M parameter) model. If your Colab instance doesn't have enough GPU space, you may need to switch to the small-size (124M parameter) model, but the results will be less impressive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dKzRORuLBNLR"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet152\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "import zipfile\n",
    "from google.colab import files\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4R3D8Mr8b54"
   },
   "source": [
    "## 1 Fine-tune a ResNet for image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFoEeTYHDq2s"
   },
   "source": [
    "### 1.1 Find a dataset to fine-tune on, and make a Dataset class (1 hr.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7z6g7a_Y84n0"
   },
   "source": [
    "#### TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P8NtFZRd5hcm"
   },
   "source": [
    "- Inherit from torch.utils.data.Dataset\n",
    "- Use a [torchvision.datasets.ImageFolder](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.ImageFolder)\n",
    "- Don't spend too long finding another dataset. Some suggestions that you are free to use:\n",
    " - https://www.kaggle.com/jessicali9530/stanford-dogs-dataset\n",
    " - https://www.kaggle.com/puneet6060/intel-image-classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TBigIUFTukeJ"
   },
   "source": [
    "#### Help for downloading kaggle datasets\n",
    "Downloading Kaggle datasets requires authentication, so you can't just download from a url. Here are some step-by-step instructions of how to get Kaggle datasets in Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_X29UC6CvwfQ"
   },
   "source": [
    "1. Create an API key in Kaggle\n",
    "    - Click on profile photo\n",
    "    - Go to 'My Account'\n",
    "    - Scroll down to the API access section and click \"Create New API Token\"\n",
    "    - `kaggle.json` is now downloaded to your computer\n",
    "\n",
    "2. Upload the API key and install the Kaggle API client by running the next cell (run it again if it throws an error the first time). Also, `files.upload()` may not work in Firefox. One solution is to expand the Files banner (indicated by the '>' tab on the left side of the page) and use that to upload the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "Mhjc0pM7jOoZ",
    "outputId": "b420614a-88c4-4ec6-ee3b-db40d64d64f2"
   },
   "outputs": [],
   "source": [
    "# Run this cell and select the kaggle.json file downloaded\n",
    "# from the Kaggle account settings page.\n",
    "from google.colab import files\n",
    "files.upload()\n",
    "# Next, install the Kaggle API client.\n",
    "!pip install -q kaggle\n",
    "# Let's make sure the kaggle.json file is present.\n",
    "!ls -lha kaggle.json\n",
    "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
    "# so move it there.\n",
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "# This permissions change avoids a warning on Kaggle tool startup.\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AGlIa4SIwEXB"
   },
   "source": [
    "3. Copy the desired dataset locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "7HtB-XdIr1EE",
    "outputId": "41cdf435-e6d2-4d3c-aade-5bd8c114c0a8"
   },
   "outputs": [],
   "source": [
    "# Example download command for dataset found here: https://www.kaggle.com/akash2907/bird-species-classification\n",
    "!kaggle datasets download -d akash2907/bird-species-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zcz0JGXjxFGe"
   },
   "source": [
    "#### Make the Dataset class\n",
    "See the implementation below for reference, and implement a dataset class for the dataset you choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "lthPlsGeK4CX",
    "outputId": "895295d6-dbfe-425f-bd75-f067daeac27b"
   },
   "outputs": [],
   "source": [
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, zip_file='bird-species-classification.zip', size=256, train=True, upload=False):\n",
    "        super(BirdDataset, self).__init__()\n",
    "        \n",
    "        self.train = train\n",
    "        extract_dir = os.path.splitext(zip_file)[0]\n",
    "        if not os.path.exists(extract_dir):\n",
    "            os.makedirs(extract_dir)\n",
    "            self.extract_zip(zip_file, extract_dir)\n",
    "            # Resize the images - originally they are high resolution. We could do this\n",
    "            # in the DataLoader, but it will read the full-resolution files from disk\n",
    "            # every time before resizing them, making training slow\n",
    "            self.resize(extract_dir, size=size)\n",
    "\n",
    "        postfix = 'train' if train else 'test'\n",
    "            \n",
    "        if train:\n",
    "            # The bird-species dataset mistakenly has a train_data folder inside of train_data\n",
    "            self.dataset_folder = datasets.ImageFolder(os.path.join(extract_dir, 'train_data', 'train_data'), transform=transforms.Compose([transforms.ToTensor()]))\n",
    "        else:\n",
    "            self.dataset_folder = datasets.ImageFolder(os.path.join(extract_dir, 'test_data', 'test_data'), transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "    def extract_zip(self, zip_file, extract_dir):\n",
    "        print(\"Extracting\", zip_file)\n",
    "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_dir)\n",
    "\n",
    "    def resize(self, path, size=256):\n",
    "        \"\"\"Resizes all images in place\"\"\"\n",
    "        print(\"Resizing images\")\n",
    "        dirs = os.walk(path)\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            for item in files:\n",
    "                name = os.path.join(root, item)\n",
    "                if os.path.isfile(name):\n",
    "                    im = Image.open(name)\n",
    "                    im = ImageOps.fit(im, (size, size))\n",
    "                    im.save(name[:-3] + 'bmp', 'BMP')\n",
    "                    os.remove(name)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.dataset_folder[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_folder)\n",
    "\n",
    "bird_data = BirdDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5jHFdToeDtIF"
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# Implement your own Dataset\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2vJVbYcAJAf2"
   },
   "source": [
    "### 1.2 Wrap a pretrained ResNet in an `nn.Module` (30 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gMOzGDND9FD1"
   },
   "source": [
    "#### TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jLvmDHbl9IyG"
   },
   "source": [
    "- Make a model class that inherits from `nn.Module`\n",
    "- Wrap a pretrained ResNet and swap out the last layer of that network with a layer that maps to the number of classes in your new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eOtl8z8G9wbr"
   },
   "source": [
    "#### Make your model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AY-XU4Mwas0j"
   },
   "outputs": [],
   "source": [
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, num_classes, start_frozen=False):\n",
    "        super(CustomResNet, self).__init__()\n",
    "\n",
    "        # Part 1.2\n",
    "        # Load the model - make sure it is pre-trained\n",
    "\n",
    "        # Part 1.4\n",
    "        if start_frozen:\n",
    "            # Turn off all gradients of the resnet\n",
    "        \n",
    "        # Part 1.2\n",
    "        # Look at the code of torchvision.models.resnet152 (or print the ResNet object) to find the name of the attribute to override (the last layer of the ResNet)\n",
    "        # Override the output linear layer of the neural network to map to the correct number of classes. Note that this new layer has requires_grad = True\n",
    "        pass\n",
    "        \n",
    "    def unfreeze(self, n_layers):\n",
    "        # Part 1.4\n",
    "        # Turn on gradients for the last n_layers\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Part 1.2\n",
    "        # Pass x through the resnet\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Krh0eYy18R9"
   },
   "source": [
    "### 1.3 Read through and run this training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOGrrw2gbIPf"
   },
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y_truth):\n",
    "    \"\"\"Gets average accuracy of a vector of predictions\"\"\"\n",
    "    \n",
    "    preds = torch.argmax(y_hat, dim=1)\n",
    "    acc = torch.mean((preds == y_truth).float())\n",
    "    return acc\n",
    "\n",
    "def evaluate(model, objective, val_loader, device):\n",
    "    \"\"\"Gets average accuracy and loss for the validation set\"\"\"\n",
    "\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    # model.eval() so that batchnorm and dropout work in eval mode\n",
    "    model.eval()\n",
    "    # torch.no_grad() to turn off computation graph creation. This allows for temporal\n",
    "    # and spatial complexity improvements, which allows for larger validation batch \n",
    "    # sizes so itâ€™s recommended\n",
    "    with torch.no_grad():\n",
    "        for x, y_truth in val_loader:\n",
    "\n",
    "            x, y_truth = x.to(device), y_truth.to(device)\n",
    "            y_hat = model(x)\n",
    "            val_loss = objective(y_hat, y_truth)\n",
    "            val_acc = accuracy(y_hat, y_truth)\n",
    "\n",
    "            val_losses.append(val_loss.item())\n",
    "            val_accs.append(val_acc)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    return torch.mean(torch.Tensor(val_losses)), torch.mean(torch.Tensor(val_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VKESMcKi2E_f"
   },
   "outputs": [],
   "source": [
    "def train(start_frozen=False, model_unfreeze=0):\n",
    "    \"\"\"Fine-tunes a CNN\n",
    "    Args:\n",
    "        start_frozen (bool): whether to start with the network weights frozen.\n",
    "        model_unfreeze (int): the maximum number of network layers to unfreeze\n",
    "    \"\"\"\n",
    "    epochs = 20\n",
    "    # Start with a very low learning rate\n",
    "    lr = .00005\n",
    "    val_every = 3\n",
    "    num_classes = 16\n",
    "    batch_size = 32\n",
    "    device = torch.device('cuda:0')\n",
    "\n",
    "    # Data\n",
    "    train_dataset = BirdDataset(upload=True, train=True)\n",
    "    val_dataset = BirdDataset(upload=True, train=False)\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              shuffle=True,\n",
    "                              num_workers=8,\n",
    "                              batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_dataset,\n",
    "                              shuffle=True,\n",
    "                              num_workers=8,\n",
    "                              batch_size=batch_size)\n",
    "    \n",
    "    # Model\n",
    "    model = CustomResNet(num_classes, start_frozen=start_frozen).to(device)\n",
    "    \n",
    "    # Objective\n",
    "    objective = nn.CrossEntropyLoss()\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-1)\n",
    "\n",
    "    # Progress bar\n",
    "    pbar = tqdm(total=len(train_loader) * epochs)\n",
    "\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    cnt = 0\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Implement model unfreezing\n",
    "        if epoch < model_unfreeze:\n",
    "            # Part 1.4\n",
    "            # Unfreeze the last layers, one more each epoch\n",
    "            pass\n",
    "        \n",
    "        for x, y_truth in train_loader:\n",
    "        \n",
    "            x, y_truth = x.to(device), y_truth.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_hat = model(x)\n",
    "            train_loss = objective(y_hat, y_truth)\n",
    "            train_acc = accuracy(y_hat, y_truth)\n",
    "\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss.item())\n",
    "\n",
    "            if cnt % val_every == 0:\n",
    "                val_loss, val_acc = evaluate(model, objective, val_loader, device)\n",
    "                val_losses.append(val_loss)\n",
    "                val_accs.append(val_acc)\n",
    "\n",
    "            pbar.set_description('train loss:{:.4f}, train accuracy:{:.4f}.'.format(train_loss.item(), train_acc))\n",
    "            pbar.update(1)\n",
    "            cnt += 1\n",
    "\n",
    "    pbar.close()\n",
    "    plt.subplot(121)\n",
    "    plt.plot(np.arange(len(train_accs)), train_accs, label='Train Accuracy')\n",
    "    plt.plot(np.arange(len(train_accs), step=val_every), val_accs, label='Val Accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(122)\n",
    "    plt.plot(np.arange(len(train_losses)), train_losses, label='Train Loss')\n",
    "    plt.plot(np.arange(len(train_losses), step=val_every), val_losses, label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvnxeLotchiH"
   },
   "outputs": [],
   "source": [
    "train(start_frozen=False, model_unfreeze=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEDv_-H7BvM0"
   },
   "source": [
    "### 1.4 Implement Unfreezing (1 hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YH5mQBaa-_0b"
   },
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u_YmE1pe-6LF"
   },
   "source": [
    "Unfreezing is a technique that can be helpful when fine tuning a CNN for a more difficult task with a large amount of data.\n",
    "\n",
    "The idea is that if we allow the network to tweak the earliest layers immediately, before the last FCL has been trained at all, the earliest layers will forget all of the useful features that they learned in order  to provide features that are helpful for the (untrained) FCL.\n",
    "\n",
    "So, rather than training all of the model weights at once, we learn the last fully connected layer, then train that layer together with the second-to-last layer, gradually adding layers until we reach the first layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XMKRI77_-8nc"
   },
   "source": [
    "#### TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KaUc8BTYC1bz"
   },
   "source": [
    "- Modify your model class by setting the `requires_grad` attribute of the ResNet to `False`. (but keep `requires_grad = True` for the last layer).\n",
    "- Add a member function to you model class that allows the user to unfreeze weights in the training loop. See [this github gist](https://gist.github.com/jcjohnson/6e41e8512c17eae5da50aebef3378a4c) for reference.\n",
    "- Modify your training loop to add logic that calls the `unfreeze` function of the model class (unfreeze one layer every epoch).\n",
    "- Call your train function to fine-tune the ResNet on your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qBT5jgifC7Im"
   },
   "source": [
    "#### Call your train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mg9ySEO_BNDx"
   },
   "outputs": [],
   "source": [
    "############################\n",
    "# train with unfreezing here (should be a single call to your train function)\n",
    "############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZItH2lX7k4Yt"
   },
   "source": [
    "You may not see any improvement for your classification task, but unfreezing can help convergence for more difficult image classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XAXHAUf3EEiE"
   },
   "source": [
    "## 2 Fine-tune a language model - (15 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yu9usOxtjFHL"
   },
   "source": [
    "In this section you will use the gpt-2-simple package [here](https://github.com/minimaxir/gpt-2-simple) to fine-tune the GPT-2 language model on a domain of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_K7F19SPQo6U"
   },
   "source": [
    "### 2.1 Generate text from an the pretrained GPT-2 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9YLXvK51RnuL"
   },
   "source": [
    "#### Run this code to generate text from a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "id": "WDNOb_H5IRvH",
    "outputId": "ee556e47-1467-42f2-f485-c4218c9e55be"
   },
   "outputs": [],
   "source": [
    "!pip install gpt-2-simple\n",
    "\n",
    "# the transformers package is built on top of Tensorflow, and the default TF version \n",
    "# for Colab will soon switch to 2.x. We remedy this with the following magic method\n",
    "%tensorflow_version 1.x \n",
    "\n",
    "import gpt_2_simple as gpt2\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6aRJ-c9uRMOa",
    "outputId": "488e8ee2-a7a4-4ec5-ac69-9db23acbb0c8"
   },
   "outputs": [],
   "source": [
    "# This line is necessary to be able to run a new tf session\n",
    "tf.reset_default_graph()\n",
    "# The medium-sized model. IF you run out of memory, try \"124M\" instead\n",
    "model_name = \"124M\"\n",
    "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
    "\tprint(f\"Downloading {model_name} model...\")\n",
    "\tgpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under /models/124M/\n",
    "\n",
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess, model_name=model_name)\n",
    "gpt2.generate(sess, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHmjSVf_FNHv"
   },
   "source": [
    "### 2.2 Download a text dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gPXJkNubFyY6"
   },
   "source": [
    "#### TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KWkuRjbcFzwb"
   },
   "source": [
    "- Use the provided functions to download your own text dataset\n",
    "- [Project Gutenberg](https://www.gutenberg.org/) is a nice starting point for raw text corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iD45m3IwF9hh"
   },
   "source": [
    "#### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ESltl2QM5nxw",
    "outputId": "d79b5612-2efb-4ab1-c156-0e7807f27140"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from torchvision import datasets\n",
    "\n",
    "def extract_zip(zip_path, remove_finished=True):\n",
    "    print('Extracting {}'.format(zip_path))\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(zip_path.replace('.zip', ''))\n",
    "    if remove_finished:\n",
    "        os.remove(zip_path)\n",
    "\n",
    "def download_dataset(url, root='../data'):\n",
    "    if not os.path.exists(os.path.join(root, 'text')):\n",
    "        os.makedirs(os.path.join(root))\n",
    "        datasets.utils.download_url(url, root, 'text.zip', None)\n",
    "        extract_zip(os.path.join(root, 'text.zip'))\n",
    "    return os.path.join(root, 'text')\n",
    "\n",
    "##########################################\n",
    "# Set the url for your dataset here,\n",
    "# move the dataset to the desired location\n",
    "##########################################\n",
    "url = 'https://www.gutenberg.org/files/30/30.zip'\n",
    "download_dataset(url)\n",
    "!mv /data/text/30.txt /data/text/bible.txt\n",
    "!ls ../data/text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "usQE-rSPZq_X"
   },
   "source": [
    "### 2.3 Fine-tune GPT-2 on your own dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IoA0tZZCa_1k"
   },
   "source": [
    "#### TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OoU6ML1mbgjP"
   },
   "source": [
    "- Swap out the dataset parameter with the path to your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8pa5vFJ5EUjv"
   },
   "source": [
    "#### Train on your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WuQ5snl4LuS0",
    "outputId": "5b5d7e2f-4dae-4313-a54b-1254b70d6ebe"
   },
   "outputs": [],
   "source": [
    "# This line is necessary to be able to run a new tf session if one has already been run\n",
    "tf.reset_default_graph()\n",
    "# Start a session\n",
    "sess = gpt2.start_tf_sess()\n",
    "# Fine tune `model_name` on `data`\n",
    "###################################\n",
    "# Swap out the `dataset` parameter with the path to your text dataset\n",
    "###################################\n",
    "gpt2.finetune(sess,\n",
    "              dataset='../data/text/bible.txt',\n",
    "              model_name=model_name,\n",
    "              restore_from='latest',\n",
    "              steps=500)   # steps is max number of training steps\n",
    "\n",
    "gpt2.generate(sess, run_name='run1')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "sBOvJdJfkXIL",
    "kFoEeTYHDq2s",
    "7z6g7a_Y84n0",
    "TBigIUFTukeJ",
    "zcz0JGXjxFGe",
    "2vJVbYcAJAf2",
    "gMOzGDND9FD1",
    "eOtl8z8G9wbr",
    "2Krh0eYy18R9",
    "aEDv_-H7BvM0",
    "YH5mQBaa-_0b",
    "XMKRI77_-8nc",
    "qBT5jgifC7Im",
    "_K7F19SPQo6U",
    "9YLXvK51RnuL",
    "AHmjSVf_FNHv",
    "gPXJkNubFyY6",
    "iD45m3IwF9hh",
    "usQE-rSPZq_X",
    "IoA0tZZCa_1k",
    "8pa5vFJ5EUjv"
   ],
   "name": "DL_Lab10",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
